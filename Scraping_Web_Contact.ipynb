{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "7-r9nN_iRxXX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bb165a5-a168-4827-db14-27f350d2efd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Facebook links found:\n",
            "https://www.facebook.com/IJS.SI/\"><img\n",
            "Instagram links found:\n",
            "https://www.instagram.com/institutjozefstefan/\"><img\n",
            "Twitter links found:\n",
            "https://twitter.com/JSI_SLO/\"><img\n",
            "No HTML contact form found\n",
            "Email addresses:\n",
            "info@ijs.si\n",
            "No phone numbers found.\n",
            "Telegram:\n",
            "2023-08-15\n",
            "No whatsapp found.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "domain = 'https://ijs.si/ijsw'\n",
        "path = 'contact/'\n",
        "extra_path = '-us'\n",
        "url = domain   #+ path + extra_path # Replace with the URL of the website you want to scrape\n",
        "\n",
        "# Send HTTP GET request\n",
        "response = requests.get(url)\n",
        "website_content = response.text\n",
        "\n",
        "def find_social_media_links(website_content):\n",
        "    # Regular expressions for Facebook, Instagram, Twitter, and YouTube URLs\n",
        "    pattern_facebook = r'(?:https?:\\/\\/)?(?:www\\.)?facebook\\.com\\/\\S+'\n",
        "    pattern_instagram = r'(?:https?:\\/\\/)?(?:www\\.)?instagram\\.com\\/\\S+'\n",
        "    pattern_twitter = r'(?:https?:\\/\\/)?(?:www\\.)?twitter\\.com\\/\\S+'\n",
        "    pattern_youtube = r'(?:https?:\\/\\/)?(?:www\\.)?youtube\\.com\\/\\S+'\n",
        "    pattern_linkedin = r'(?:https?:\\/\\/)?(?:www\\.)?linkedin\\.com\\/\\S+'\n",
        "\n",
        "    # Find all matches using regular expressions\n",
        "    matches_facebook = re.findall(pattern_facebook, website_content, re.IGNORECASE)\n",
        "    matches_instagram = re.findall(pattern_instagram, website_content, re.IGNORECASE)\n",
        "    matches_twitter = re.findall(pattern_twitter, website_content, re.IGNORECASE)\n",
        "    matches_youtube = re.findall(pattern_youtube, website_content, re.IGNORECASE)\n",
        "    matches_linkedin = re.findall(pattern_linkedin, website_content, re.IGNORECASE)\n",
        "\n",
        "    # Return the detected social media links\n",
        "    social_media_links = {\n",
        "        \"Facebook\": matches_facebook,\n",
        "        \"Instagram\": matches_instagram,\n",
        "        \"Twitter\": matches_twitter,\n",
        "        \"LinkedIn\": matches_linkedin,\n",
        "        \"YouTube\": matches_youtube\n",
        "\n",
        "    }\n",
        "\n",
        "    return social_media_links\n",
        "\n",
        "# Call the find_social_media_links function\n",
        "social_media_links = find_social_media_links(website_content)\n",
        "\n",
        "\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    # Parse the HTML content\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Search for contact information using regex patterns\n",
        "    contact_info = soup.get_text()  # Get all text content from the page\n",
        "    email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'  # Regex pattern for email addresses\n",
        "    phone_pattern = r'\\b(?:\\+?(\\d{1,3}))?[-. (]?(\\d{3})[-. )]?(\\d{3})[-. ]?(\\d{4})\\b'  # Regex pattern for phone numbers\n",
        "    telegram_pattern = r'\\b(?:\\+\\d{1,3}[-. ])?\\(?[0-9]{2}\\)?[-. ]?(?:[0-9]{2}[-. ]?){2}[0-9]{2}\\b'  # Regex pattern for telegram\n",
        "    whatsapp_pattern = r'\\b(?:\\+\\d{1,3}[-. ]?)?[1-9]\\d{0,2}[-. ]?\\d{2,3}[-. ]?\\d{4}\\b'# Regex pattern for whatsapp\n",
        "\n",
        "\n",
        "    # Extract email addresses using the email pattern\n",
        "    emails = re.findall(email_pattern, contact_info)\n",
        "\n",
        "    # Extract phone numbers using the phone pattern\n",
        "    phone_numbers = re.findall(phone_pattern, contact_info)\n",
        "\n",
        "    # Extract phone numbers using the phone pattern\n",
        "    telegram_no = re.findall(telegram_pattern, contact_info)\n",
        "\n",
        "    # Extract phone numbers using the phone pattern\n",
        "    whatsapp_no = re.findall(whatsapp_pattern, contact_info)\n",
        "\n",
        "    # Print the detected social media links\n",
        "    for platform, links in social_media_links.items():\n",
        "      if links:\n",
        "          print(f\"{platform} links found:\")\n",
        "          for link in links:\n",
        "            print(link)\n",
        "    # Search for contact form\n",
        "    form_tags = soup.find_all('form')\n",
        "    for form in form_tags:\n",
        "        if 'contact' in str(form).lower():\n",
        "            print(\"Found HTML contact form\")\n",
        "            break\n",
        "    else:\n",
        "        print(\"No HTML contact form found\")\n",
        "\n",
        "    # Print the extracted contact information\n",
        "    if emails:\n",
        "        print('Email addresses:')\n",
        "        for email in emails:\n",
        "            print(email)\n",
        "    else:\n",
        "        print('No email addresses found.')\n",
        "\n",
        "    if phone_numbers:\n",
        "        print('Phone numbers:')\n",
        "        for phone in phone_numbers:\n",
        "            print(phone)\n",
        "    else:\n",
        "        print('No phone numbers found.')\n",
        "\n",
        "    if telegram_no:\n",
        "        print('Telegram:')\n",
        "        for telegram in telegram_no:\n",
        "            print(telegram)\n",
        "    else:\n",
        "        print('No telegram found.')\n",
        "\n",
        "    if whatsapp_no:\n",
        "      print('Whatsapp:')\n",
        "      for whatsapp in whatsapp_no:\n",
        "            print(whatsapp)\n",
        "    else:\n",
        "        print('No whatsapp found.')\n",
        "\n",
        "else:\n",
        "    print('Failed to retrieve website content.')\n",
        "    print('404')\n",
        "\n"
      ]
    }
  ]
}